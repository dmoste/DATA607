library(ggplot2)
library(tidyverse)
library(ranger)
library(missRanger)
library(data.table)
library(abind)
library(mongolite)

setwd("~/R")
# read the data in and do a bit of cleaning
df <- read.csv("all_transcripts.csv") %>%
  separate(Table, c("Code","GPA.Modify"), sep = "\\*") %>%
  select(-GPA.Modify,
         -Term.Average.Display,
         -Credits.Total,
         -Credit.Earned.Total,
         -Credits.Average,
         -Credits.Total.1,
         -Cumulative.Term.Average1,
         -Mark.1,
         -Credits.Average.1,
         -Credit.Earned.Total.1,
         -CreditEarned.1,
         -Mark,
         -CreditEarned) %>%
  mutate(College = ifelse(grepl("U$", Code) | Code == "HBS11UA", "Y", "N")) %>%
  tbl_df()

my_collection = mongo(collection = "attendance", db = "final")
attendance <- my_collection$find('{}')

# StudentID is only listed for the last instance of each student. This section of
# code pulls up that ID number through all the rows of a student. I then converted
# all the course codes into usable names as columns so that the ranger package can
# use them as features later.
df$StudentID <- nafill(df$StudentID, type = "nocb")
df$Code <- make.names(df$Code, unique = FALSE, allow_ = FALSE)

# This makes each course code a feature for ranger and takes the max score a
# student received in a course as the official score.
df <- df %>%
  pivot_wider(names_from  = Code,
              values_from = NumericEquivalent) %>%
  group_by(StudentID) %>%
  left_join(attendance, by = "StudentID") %>%
  summarise_if(is.numeric,
               max,
               na.rm = TRUE)

# In this step, I converted all the -Inf generated by the summarise_if statement
# into NAs so that they could then be imputed by missRanger.
df[df == -Inf] <- NA
df <- df[, which(colMeans(!is.na(df)) > 0.05)]
df <- df %>%
  mutate(Imputed = ifelse(is.na(df$MQS11U), 1, 0)) %>%
  select(-TermCD, -SchoolYear)

df <- missRanger(df, num.trees = 100, maxiter = 5)

filled <- replicate(100,
                    missRanger(df,
                               num.trees = 100,
                               maxiter   = 3),
                    simplify = FALSE)

temp_array <- abind(filled, along = 3)
df <- data.frame(apply(temp_array, 1:2, mean))

# This step creates the training and holdout datasets for ranger
sample_size = floor(0.75*nrow(df))
picked      = sample(seq_len(nrow(df)),
                     size = sample_size)
training    = df[picked,]
holdout     = df[-picked,]

# Create a grid of possible random forest values to determine which are best for
# this dataset.
hyper_grid <- expand.grid(
  mtry       = seq(1, 116, by = 5),
  node_size  = seq(1, 9, by  = 2),
  sampe_size = c(0.632, 0.70, .80),
  OOB_RMSE   = 0
)

# Run through the list of possible values to get an idea of what values each
# parameter should take to get the best model. This can take about 40 hours to run
system.time(
  for(i in 1:nrow(hyper_grid)){
    model <- ranger(
      formula         = MQS11U ~ ., 
      data            = training, 
      num.trees       = 500,
      mtry            = hyper_grid$mtry[i],
      min.node.size   = hyper_grid$node_size[i],
      sample.fraction = hyper_grid$sampe_size[i],
      seed            = 123)
    hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
  }
)

hyper_grid %>% 
  arrange(OOB_RMSE) %>%
  head(10)

OOB_RMSE <- vector(mode = "numeric", length = 100)

# Use the best parameter values to create 100 different models
for(i in seq_along(OOB_RMSE)) {
  optimal_ranger <- ranger(
    formula         = MQS11U ~ ., 
    data            = training, 
    num.trees       = 500,
    mtry            = 36,
    min.node.size   = 1,
    sample.fraction = .8,
    importance      = 'impurity')
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

importance <- data.frame(optimal_ranger$variable.importance)
setDT(importance, keep.rownames = TRUE)[]
names(importance) <- c("Variable", "Value")

importance %>%
  arrange(desc(Value)) %>%
  top_n(20) %>%
  ggplot(aes(reorder(Variable, Value), Value)) +
  geom_col() +
  coord_flip() +
  ggtitle("Top 20 important variables")

pred_ranger <- predict(optimal_ranger, holdout)
plot(pred_ranger[["predictions"]], holdout$MQS11U)

m_all <- lm(holdout$MQS11U ~ pred_ranger[["predictions"]])
summary(m_all)
abline(m_all)

pf <-data.frame(holdout, pred_ranger[["predictions"]])
pf$Imputed <- as.factor(pf$Imputed)
ggplot(pf,
       aes(x     = pred_ranger...predictions...,
           y     = MQS11U,
           color = Imputed)) + geom_point()

pf <- filter(pf, Imputed == 0)
ggplot(pf,
       aes(x     = pred_ranger...predictions...,
           y     = MQS11U,
           color = Imputed)) + geom_point()
plot(pf$pred_ranger...predictions..., pf$MQS11U)
m_real <- lm(pf$MQS11U ~ pf$pred_ranger...predictions...)
summary(m_real)
abline(m_real)

saveRDS(optimal_ranger, "big_model.rds")

###################################################################################

loaded_model <- readRDS("big_model.rds")
full_pred <- predict(loaded_model, df)
plot(full_pred[["predictions"]], df$SPS21)

m_all <- lm(df$SPS21 ~ full_pred[["predictions"]])
summary(m_all)
abline(m_all)

filtered_df <-data.frame(df, full_pred[["predictions"]])
filtered_df <- filter(filtered_df, Imputed == 0)
filtered_df$Imputed <- as.factor(filtered_df$Imputed)

ggplot(filtered_df,
       aes(x     = full_pred...predictions...,
           y     = SPS21,
           color = Imputed)) + geom_point()
plot(filtered_df$full_pred...predictions..., filtered_df$SPS21)
m_all_real <- lm(filtered_df$SPS21 ~ filtered_df$full_pred...predictions...)
summary(m_all_real)
abline(m_all_real)
